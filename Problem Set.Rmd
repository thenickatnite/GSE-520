---
title: 'GSE 520: Problem Set #18'
author: 
  - "student name"
output: html_document
---

Governments of countries with low or declining birth rates will often offer their citizens an incentive to have children. This was the case in Spain, so in 2007 the Spanish government implemented a universal child benefit. This benefit gave new mothers a one-time payment of around $\$3,900$ almost immediately after child birth. The universal child benefit went into effect in July of 2007 and after it was announced, any mother who had given birth on or after July 1, 2007 was eligible to receive the benefit. In "The Effect of a Universal Child Benefit on Conceptions, Abortions, and Early Maternal Labor Supply", author Libertad Gonzalez uses a regression discontinuity design to see if the number of conceptions (among other things, you'll be replicating the conception estimates for this problem set) increased following the implementation of the benefit. You can find the data set for this paper in data file titled: ```births.RData```.

The data set consists of estimated conceptions per month from 2000 to 2009, this is represented as the variable $n$ in the data set. The variable $log\_n$ is the log number of estimated conceptions per month. The month of conception variable $mc$, has been standardized using the July 2007 policy implementation date (so for July of 2007 $mc=0$, August of 2007 $mc=1$, June of 2007 $mc=-1$, etc.). There are also $mc2$ and $mc3$ variables which represent the quadratic and cubic trends of the linear $mc$ variable. Another variable is the $days$ variable which represents the number of days in the month of conception. The variable of interest in the paper is the $post$ variable, a binary variable which is $1$ if the $mc$ is after July 2007 and $0$ if the $mc$ is before July 2007.

### Question 1  

A regression discontinuity design (RDD) is a powerful method for finding causal effects using regression. In order to use a sharp RDD, what factors must your research question have?

>**Solution:**
In order to use a sharp RDD, you must some sort of circumstance where there is a strict cutoff and once past that cutoff, individuals receive a treatment of some kind. Examples include drinking age laws, height requirements for rides, etc. In a sharp RDD you use this cutoff to explain some other event. In the book, that was an increase in death rate following an individual turning 21. 


### Question 2  

(a) Let's start by getting summary statistics for the $log\_n$ and $post$ variables and replicating the initial regression from the aforementioned paper. You will first need to subset the data from $mc=-90$ to $mc = 29$. Your subset should consist of 120 observations. Estimate a regression of the form: 
$$log\_n = \beta_0 + \beta_1 post + \beta_2 mc + \beta_3 mc2 + \beta_4 mc3 + \beta_5 days$$
Print the summary statistics of $log\_n$ and $post$, as well as the summary of the coefficients, t-scores, and p-values (make sure you use robust standard errors) from the regression you ran. Anything surprising or weird with the summary statistics? What estimates are significant? Do a formal hypothesis test for $mc$, is the estimate significantly different than zero at the $5\%$ significance level?

>**Solution:**  
>```{R}
load('births.RData')
suppressMessages(library("AER"))
# Summary statistics for log_n
summary(n$log_n)
# Summary statistics for post
summary(n$post)
# regression and summary
subset1 = n[n$mc > -91 & n$mc < 30, ]
mod1 = lm(log_n ~ factor(post) + mc + mc2 + mc3 + days, data = subset1)
round(coeftest(mod1, vcov. = vcovHC(mod1, "HC0")), 5)
# hypothesis test for mc
obs = length(subset1$log_n)
CV = abs(qt(.05/2, obs))
CV
```
>
>Summary stats seem normal.
>
>All variables are significant except for the $days$ and $mc$ variables. All the other variables are significant at the $1\%$ significance level.
> The critical value for the hypothesis test is the absolute value of 1.979. The t-value for $mc$ is -1.6238 so we cannot reject the null hypothesis. We fail to reject the null hypothesis that the estimate for $mc$ is significantly different than zero.




(b) Interpret the coefficient of $\beta_1$. What effect does the universal child benefit appear to have on conceptions in Spain? Does this effect make economic sense?

>**Solution:**  
The estimate for $\beta_1$ is equal to $0.0498$. This implies that after the policy went into effect (and $post=1$) that the estimated conceptions increased by about $5\%$. This effect does make economic sense. You would expect those who were on the fence about getting pregnant potentially being swayed by the benefit they would receive from having the baby. There is now more of an incentive to having a child.


(c) Let's graph the data and regression lines and see if a clear discontinuity shows itself in the graph. The lines generated will be done using the loess smoother, both for aesthetic and ease of code reasons. For this question you will need to download and attach the ```ggplot2``` package in R. Here is an example of the code you can use to plot the data: 
```
ggplot(first_subset (this should be whatever the name of your subset is), aes(x = mc, y = log_n, colour = factor(post))) + 
  geom_point() + 
  xlab("Month of Conception Before/After July 2007") + 
  ylab("Log Number of Conceptions") + 
  ggtitle("Estimated Number of Log Conceptions Per Month") + 
  stat_smooth(method = loess)
```
Plot the graph and then interpret what you see. Is there a clear discontinuity following the policy implementation (is there a jump in estimated conceptions)? What are the implications if a clear discontinuity does not appear graphically?

>**Solution:**  
>```{R}
suppressMessages(library("ggplot2"))
ggplot(subset1, aes(x = mc, y = log_n, colour = factor(post))) + 
  geom_point() + 
  xlab("Month of Conception Before/After July 2007") + 
  ylab("Log Number of Conceptions") + 
  ggtitle("Estimated Number of Log Conceptions Per Month") + 
  stat_smooth(method = loess)
```
>
>Yes. There appears to be a clear discontinuity following implementation of the policy. The graph shows a jump in estimated conceptions following the policy implementation.
>
>If there appears to be no discontinuity graphically, a researcher will likely need to revaluate their method, as their research question may not fit a RD design. Or find a new cutoff point, or variable to model the discontinuity. Nonetheless, a lack of clear discontinuity should be a red flag for the researcher.


(d) A strategy to limit RD mistakes is to focus on observations near the cutoff. In the paper, the author restricts the data set multiple times and reports what happens to the estimate of the variable of interest $post$. Another way to check the robustness of the estimates is to change the model, whether that be adding or removing a variable.

For this next regression, repeat what you did in part (a), but remove the cubic term $mc3$ and restrict the data set from $mc=-30$ to $mc=29$. You should have 60 observations. Again, use robust standard errors. Report on any changes in the estimates from part (a). Do your estimates (particularly for the treatment variable) appear to be robust? Do a formal hypothesis test and test whether the estimate for the $post$ variable is significantly different than zero at the $5\%$ significance level.

>**Solution:**
>```{R}
subset2 = n[n$mc>-31 & n$mc<30, ]
mod2 = lm(log_n ~ factor(post) + mc + mc2 + days, data = subset2)
round(coeftest(mod2, vcov. = vcovHC(mod1, type = "HC0")), 5)
# critical value for hypothesis test
obs = length(subset2$log_n)
CV = abs(qt(.05/2, obs))
CV
```
>
>The $mc$ variable is now significant. The estimate for $post$ appears to be robust as the estimate only changed slightly and is still significant at the $1\%$ significance level.
The t-value for $post$ is 2.8261, greater than the critical value of 2.00. Therefore we can reject the null hypothesis that the estimate of $post$ is equal to zero at the $5\%$ significance level.

(e) Finally, restrict the data set from $mc=-12$ to $mc=11$. Run the same regression from part (d) with robust standard errors. What are the results, any changes from part (d)? Do our estimators seem robust as we restrict the sample size, and change the model specification?

>**Solution:**
>```{R}
subset3 = n[n$mc>-13 & n$mc<12, ]
mod3 = lm(log_n ~ factor(post) + mc + mc2 + days, data = subset3)
round(coeftest(mod3, vcov. = vcovHC(mod3, "HC0")), 5)
```
>
>$post$ and $mc2$ are still significant. $post$ is still significant at $5\%$ significance level, but no longer at the $1\%$ significance level. The estimates seem to be robust, as the variable of interest $post$ is significant in each regression, and the sign is what we would expect it to be each time.

(f) Explain a potential issue with using non-parametric RD like we just did for the past two regressions? Use equation 4.5 from book (on p.162) to help answer this question.

>**Solution:**
Non-parametric RD allows for a trade off in the bias for an increase in variance due to the decrease in number of observations. However, as you decrease the bandwidth there are not enough observations to make accurate estimates. 
$$ a_0 - b \leq a \leq a_0 + b$$
This is the equation for picking a non-parametric RD. As the bandwidth ($b$) gets smaller, the number of observations of $a$ decreases. While this can reduce bias (and non-linear trends), this also limits the number of observations that can be used for analysis around the cutoff leading to less accurate estimates.

### Question 3

(a) The regressions you just replicated are an example of a sharp RD design. Sharp RD is not the only kind of regression discontinuity design, a researcher can also use a fuzzy regression discontinuity design. From what you read in the chapter, when should researchers use a fuzzy RD as opposed to a sharp RD?

**Solution:**
A fuzzy RD is used when the cutoff point leads to a higher intensity treatment, as opposed to a sharp RD where the cutoff differentiated between the control and the treatment. In the book, the fuzzy RD was shown through exam schools in Boston where the cutoff was test scores to get into the most prestigious exam school.


(b) When using a Fuzzy RD as compared to a Sharp RD, which regression would you expect to give you more significant estimates (estimates that are significantly different than zero) and why? Explain why one design will like be superior in generating significant estimates.

**Solution:**
We would expect the Sharp RD to give us more significant estimates. This is because Fuzzy RD uses instrumental variables and two stage least squares regression, and that process increases the size of standard errors. Sharp RD uses straightforward OLS regression, and those standard errors will typically be smaller than any 2SLS regression standard errors.

